# summarize_audio.py
# whisper í…ŒìŠ¤íŠ¸ìš©
# ì „ì²´ íŒŒì´í”„ë¼ì¸ì—ì„œëŠ” ì‚¬ìš©ë˜ì§€ ì•ŠìŒ.
import whisper
from openai import OpenAI
from dotenv import load_dotenv
import os

load_dotenv()
client = OpenAI()

# 1. Whisperë¡œ ìŒì„± íŒŒì¼ STT
def transcribe_audio(file_path):
    model = whisper.load_model("base")
    result = model.transcribe(file_path)
    return result["text"]

# 2. GPTë¡œ ìš”ì•½
def summarize_text(transcript):
    messages = [
        {"role": "system", "content": (
                "You are a kind and knowledgeable assistant who summarizes doctor-patient consultations. "
                "Your goal is to explain the important points in a way that a person without medical knowledge can understand. "
                "Focus on clearly summarizing the health concerns and medical advice from the consultation in simple, non-technical language. "
                "Avoid using medical jargon. Be concise, friendly, and easy to understand."
            )},
        {"role": "user", "content": (
            "ë‹¤ìŒì€ ì˜ì‚¬ì™€ í™˜ìì˜ ìƒë‹´ ë…¹ìŒì…ë‹ˆë‹¤. ì˜í•™ ì§€ì‹ì´ ì—†ëŠ” ì‚¬ëŒì´ ìì‹ ì˜ ê±´ê°• ìƒíƒœë¥¼ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡, ì¤‘ìš”í•œ ì¦ìƒ, ì§„ë‹¨, ì²˜ë°© ë˜ëŠ” ì˜ì‚¬ì˜ ì¡°ì–¸ì„ ê°„ë‹¨í•˜ê³  ëª…í™•í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”. ìš”ì•½ ì–¸ì–´ëŠ” ë…¹ìŒë³¸ê³¼ ë™ì¼í•œ ì–¸ì–´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.:\n\n" + transcript
        )}
    ]
    response = client.chat.completions.create(
        model="gpt-4",
        messages=messages
    )
    return response.choices[0].message.content

if __name__ == "__main__":
    file_path = "consultation.mp3" 
    print("ğŸ™ï¸ ìŒì„± ì¸ì‹ ì¤‘...")
    transcript = transcribe_audio(file_path)
    print("ğŸ“ ìš”ì•½ ì¤‘...")
    summary = summarize_text(transcript)
    print("âœ… ìš”ì•½ ê²°ê³¼:")
    print(summary)
